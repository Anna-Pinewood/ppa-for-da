{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Отбор_признаков_Рубан_Александр.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubanZ/ppa-for-da/blob/master/students/%D0%A0%D1%83%D0%B1%D0%B0%D0%BD_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80/%D0%9E%D1%82%D0%B1%D0%BE%D1%80_%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGcIKlu6zabm"
      },
      "source": [
        "#Отбор признаков на примере датасета об сердечно-сосудистых заболеваниях\n",
        "\n",
        "Датасет: https://www.kaggle.com/rishidamarla/heart-disease-prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OlXCHh_zOTF"
      },
      "source": [
        "#Введение\n",
        "Данные могут содержать большой объем признаков. И не всегда весь объем необъодим для выполнения задачи. Критерий отбора признаков включает релевантность для целей анализа данных, качество и технические ограничения, такие как объем данных или тип данных.\n",
        "\n",
        "Удаление избыточных признаков позволяет лучше понять данные, а также сократить время настройки модели, улучшить её точность и облегчить интерпретируемость.\n",
        "\n",
        "Сильно коррелированные друг с другом переменные дают модели одну и ту же информацию, следовательно, для анализа не нужно использовать их все. Если использовать, то модель окажется переобучена (overfit) и предвзята относительно одного отдельного признака.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZKlC3r_-Hp9"
      },
      "source": [
        "###*РЕВЬЮ*\n",
        "*Опечатка - \"необъодим\"*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmI7pBIy1opk"
      },
      "source": [
        "#Методы фильтрации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBD4HlSS4kOF"
      },
      "source": [
        "Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB-PaJLp4RqW",
        "outputId": "4b5a317d-1cd8-4334-ed9b-c3f48c1f7952"
      },
      "source": [
        "pip install numpy pandas matplotlib sklearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcXzXpQW4tAA"
      },
      "source": [
        "Импорт библиотек и данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "zGvQuH_o5aIQ",
        "outputId": "205a2f74-f3ca-4973-ffce-53d32f1ca672"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest,chi2,RFE, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "df = pd.read_csv(\"Heart_Disease_Prediction.csv\")\n",
        "\n",
        "print('Размер Dataframe:', df.shape)\n",
        "print(df.head(5))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-263d64df2c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRFE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_classif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Heart_Disease_Prediction.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Размер Dataframe:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Heart_Disease_Prediction.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO-kgndc5s7l"
      },
      "source": [
        "print('\\n\\nИнформация о Dataframe df.info():')\n",
        "print(df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFVNVL7P57Fu"
      },
      "source": [
        "label = df[\"Heart Disease\"]\n",
        "df.drop(\"Heart Disease\", axis=1, inplace=True)\n",
        "print('\\n\\nЗначение метки \"Сердечное заболевание\":')\n",
        "print(label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvym7qQf6NTk"
      },
      "source": [
        "label.value_counts().plot(kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6BzFuC672V"
      },
      "source": [
        "Изменение типов данных для признаков, имеющих категориальный характер. Однако, при печати столбцов (\"Sex\", \"Chest pain type\", \"FBS over 120\", \"EKG results\", \"Exercise angina\", \"Slope of ST\", \"Number of vessels fluro\", \"Thallium\") мы наблюдаем, что они определяются, как данные целого типа и рассматриваются как целые числа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFCqhnsE6b7E"
      },
      "source": [
        "categorical_features = [\"Sex\", \"Chest pain type\", \"FBS over 120\", \"EKG results\", \"Exercise angina\", \"Slope of ST\", \"Number of vessels fluro\", \"Thallium\"]\n",
        "df[categorical_features] = df[categorical_features].astype(\"category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWQyxUJP7hKl"
      },
      "source": [
        "Теперь будем масштабировать наши непрерывные функции с помощью MinMaxScaler. Это тип нормализации, когда значения загоняются в диапазоне от 0 до 1, согласно уравнению (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl0q00xq7cmf"
      },
      "source": [
        "continuous_features = set(df.columns) - set(categorical_features)\n",
        "scaler = MinMaxScaler()\n",
        "df_norm = df.copy()\n",
        "df_norm[list(continuous_features)] = scaler.fit_transform(df[list(continuous_features)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C-ev6JA72Mj"
      },
      "source": [
        "##Отбор признаков с использованием рекурсивного исключения признаков (RFE)\n",
        "RFE является широко используемой техникой/алгоритмом для выбора точного числа значимых признаков. Иногда метод используется, чтобы объяснить некоторое число «самых важных» признаков, влияющих на результаты; а иногда для уменьшения очень большого числа переменных (около 200-400), и оставляются только те, которые вносят хоть какой-то вклад в модель, а все остальные исключаются. RFE использует ранговую систему. Признакам в наборе данных выставляются ранги. Затем эти ранги используются для рекурсивного исключения признаков в зависимости от коллинеарности между ними и значимости этих признаков в модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfI2GKLO7_as"
      },
      "source": [
        "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
        "rfe_norm = df_norm\n",
        "X_new = rfe.fit_transform(rfe_norm, label)\n",
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp7HNh0Q8NUc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxZvpLbJ9krJ"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(rfe_norm, label)\n",
        "# create a figure to plot a bar, where x axis is features, and Y indicating the importance of each feature\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.bar(rfe_norm.columns, clf.feature_importances_)\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS-BwxsA9uep"
      },
      "source": [
        "Гистограмма показывает важность каждого признака (атрибута, измерения, набора данных). В нашем случае Thallium и Number of vessels fluro являются наиболее важными характеристиками, но большинство из них имеют важное значение, и в этом случае в значительной степени стоит передать эти признаки нашей модели машинного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPmfcGoLAGgq"
      },
      "source": [
        "#Отбор по методу X^2\n",
        "Отбор признков с помощью хи-квадрат для каждого неотрицательного объекта и класса. Эта оценка может использоваться для выбора функций n_features с наивысшими значениями для тестовой статистики хи-квадрат из X, которая должна содержать только неотрицательные функции, такие как логические значения или частоты (например, количество терминов в классификации документа), относительно классы. Использование этой функции «отсеивает» признаки, которые с наибольшей вероятностью будут независимыми от класса и, следовательно, не имеют отношения к классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u248PtAlASmX"
      },
      "source": [
        "x2_norm = df_norm\n",
        "X_new = SelectKBest(k=5, score_func=chi2).fit_transform(x2_norm, label)\n",
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1myzELA4t2"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(x2_norm, label)\n",
        "# Вывод\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.bar(x2_norm.columns, clf.feature_importances_)\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCthcm46E1g8"
      },
      "source": [
        "В этом случае Chest pain type и Thllium являются наиболее важными характеристиками."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egcIVxD2GZBM"
      },
      "source": [
        "#ANOVA\n",
        "Дисперсионный анализ (ANOVA) может определить, различаются ли средние значения трех или более групп. ANOVA использует F-тесты для статистической проверки равенства средних."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdcIemb-FjQC"
      },
      "source": [
        "anova_norm = df_norm\n",
        "X_new = SelectKBest(k=5, score_func=f_classif).fit_transform(anova_norm, label)\n",
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhFkYtYVGGWB"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(anova_norm, label)\n",
        "# Вывод\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.bar(anova_norm.columns, clf.feature_importances_)\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS1nQ1MvGR-S"
      },
      "source": [
        "В этом случае Chest pain type и Thllium являются наиболее важными характеристиками."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GFJJZYc-IV6"
      },
      "source": [
        "#Источники:\n",
        "\n",
        "https://habr.com/ru/post/550978/\n",
        "\n",
        "https://tproger.ru/translations/feature-engineering-in-machine-learning/\n",
        "\n",
        "http://www.machinelearning.ru/wiki/index.php?title=CRISP-DM/Data_Preparation\n",
        "\n",
        "https://waksoft.susu.ru/2021/02/09/otbor-priznakov-s-pomoshhyu-scikit-learn-v-python/\n",
        "\n",
        "https://en.wikipedia.org/wiki/Chi-squared_distribution\n",
        "\n",
        "https://blog.minitab.com/en/adventures-in-statistics-2/understanding-analysis-of-variance-anova-and-the-f-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-jRz2R5_tr6"
      },
      "source": [
        "#Ревью. Итоги.\n",
        "\n",
        "Минусы:\n",
        "*   Не запустилось \"по клику\", нужно самому загружать датасет\n",
        "\n",
        "Плюсы:\n",
        "*  Можно выделить логическую структуру\n",
        "*  Есть список источников\n",
        "*  Есть ссылка на датасет\n",
        "\n",
        "Итог: Хороший туториал, можно добавить автоматическую загрузку и распаковку датасета. Можно дать больше ссылок внутри туториала на каждый конкретный метод.\n",
        "\n"
      ]
    }
  ]
}