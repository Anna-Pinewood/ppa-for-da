{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ITMO_FS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mash1negun/ppa-for-da/blob/AddingFile/students/%D0%9C%D0%B0%D0%BC%D0%B0%D1%88%D0%B5%D0%B2_%D0%97%D0%B0%D0%B2%D1%83%D1%80/ITMO_FS(%D0%A0%D0%B5%D0%B2%D1%8C%D1%8E%20%D0%BD%D0%B0%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%83%20%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D1%8F%20%D0%A1%D1%82%D1%80%D0%BE%D0%BA%D0%BE%D0%B2%D0%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYmEi2rn9Z6U"
      },
      "source": [
        "ITMO_FS разработали студенты и сотрудники лаборатории Машинного обучения Университета ИТМО. Она реализована на Python и совместима со scikit-learn, которая де-факто считается основным инструментом анализа данных. Ее селекторы признаков принимают те же параметры:\n",
        "\n",
        "data: array-like (2-D list, pandas.Dataframe, numpy.array);  \n",
        "targets: array-like (1-D list, pandas.Series, numpy.array).\n",
        "\n",
        "Библиотека поддерживает все классические подходы к отбору признаков — фильтры, обертки и встраиваемые методы. Среди них числятся такие алгоритмы, как фильтры на основе корреляций Спирмена и Пирсона, критерий соответствия (Fit Criterion), QPFS, hill climbing filter и другие.\n",
        "\n",
        "Рассмотрим некоторые методы, которые предоставляет эта библиотека"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "VFxVcdYu9eCX",
        "outputId": "102a8307-facc-4fa5-db07-10a4c6670710"
      },
      "source": [
        "!pip install ITMO_FS\n",
        "import ITMO_FS \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ITMO_FS\n",
            "  Downloading ITMO_FS-0.3.3-py3-none-any.whl (70 kB)\n",
            "\u001b[K     ,████████████████████████████████, 70 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.0.1)\n",
            "Collecting qpsolvers\n",
            "  Downloading qpsolvers-1.7.1-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.19.5)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn->ITMO_FS) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn->ITMO_FS) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ITMO_FS) (3.0.0)\n",
            "Requirement already satisfied: Cython>=0.29.22 in /usr/local/lib/python3.7/dist-packages (from qpsolvers->ITMO_FS) (0.29.24)\n",
            "Requirement already satisfied: qdldl>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from qpsolvers->ITMO_FS) (0.1.5.post0)\n",
            "Collecting quadprog>=0.1.8\n",
            "  Downloading quadprog-0.1.10.tar.gz (121 kB)\n",
            "\u001b[K     ,████████████████████████████████, 121 kB 8.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     ,████████████████████████████████, 15.7 MB 50.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: quadprog\n",
            "  Building wheel for quadprog (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quadprog: filename=quadprog-0.1.10-cp37-cp37m-linux_x86_64.whl size=290732 sha256=5c5f6d91384c5a2acf5175105e608a87182be00afd03655379a10cb64944e20c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/af/76/c5335ed32afc1284e6100b86588d1f75f5c4906fa26df6efda\n",
            "Successfully built quadprog\n",
            "Installing collected packages: numpy, quadprog, qpsolvers, ITMO-FS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed ITMO-FS-0.3.3 numpy-1.21.4 qpsolvers-1.7.1 quadprog-0.1.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck-EhjoG-GpD"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from ITMO_FS.filters.univariate import select_best_percentage, select_k_best\n",
        "from ITMO_FS.filters.univariate import UnivariateFilter\n",
        "from ITMO_FS.filters.univariate import f_ratio_measure, pearson_corr\n",
        "from ITMO_FS.filters.univariate import VDM\n",
        "from ITMO_FS.filters.multivariate import MRMR\n",
        "from ITMO_FS.filters.multivariate import DISRWithMassive\n",
        "from ITMO_FS.filters.unsupervised.trace_ratio_laplacian import TraceRatioLaplacian\n",
        "\n",
        "x, y = make_classification(1000, 100, n_informative = 10, n_redundant = 30, n_repeated = 10, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OXblZ1GjA6D"
      },
      "source": [
        "# Univariate filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIIHrGWMjEsm"
      },
      "source": [
        "[Value Difference Metric](https://www.jair.org/index.php/jair/article/view/10182/24168#page=6) (VDM) - метрика расстояния, использующаяся в некоторых алгоритмах n ближайших соседей. Может использоваться для снижения влияния параметров, слабо связанных с целевой переменной, на эффективность классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egmH3KIi5TI",
        "outputId": "510081ca-3a2e-4481-c8d7-2295ef474d6e"
      },
      "source": [
        "x_1 = np.array([[0, 0, 0, 0],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 0, 0, 2]])\n",
        "y_1 = np.array([0,\n",
        "              1,\n",
        "              1])\n",
        "vdm = VDM()\n",
        "vdm.run(x_1, y_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 4.35355339, 4.        ],\n",
              "       [4.5       , 0.        , 0.5       ],\n",
              "       [4.        , 0.35355339, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSSqN755bZ4e"
      },
      "source": [
        "# Measures for univariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaM_BPkobr4K"
      },
      "source": [
        "Для этой группы методов достаточно передать входные данные и их классы. Всего в группе есть 10 методов:\n",
        "\n",
        "\n",
        "1. filters.univariate.**f_ratio_measure**(X, y)\t- Calculates Fisher score for features.\n",
        "2. filters.univariate.**gini_index**(X, y)\t- Gini index is a measure of statistical dispersion.\n",
        "3. filters.univariate.**su_measure**(X, y)\t- SU is a correlation measure between the features and the class calculated, via formula SU(X,Y) = 2 * I(X,Y) / (H(X) + H(Y))\n",
        "4. filters.univariate.**spearman_corr**(X, y)\t- Calculates spearman correlation for each feature.\n",
        "5. filters.univariate.**pearson_corr**(X, y)\t- Calculates pearson correlation for each feature.\n",
        "6. filters.univariate.**fechner_corr**(X, y)\t- Calculates Sample sign correlation (Fechner correlation) for each feature.\n",
        "7. filters.univariate.**kendall_corr**(X, y)\t- Calculates Sample sign correlation (Kendall correlation) for each feature.\n",
        "8. filters.univariate.**reliefF_measure**(X, y[, …])\t- Counts ReliefF measure for each feature\n",
        "9. filters.univariate.**chi2_measure**(X, y)\t- Calculates score for the test chi-squared statistic from X.\n",
        "10. filters.univariate.**information_gain**(X, y)\t- Calculates mutual information for each feature by formula, I(X,Y) = H(X) - H(X,Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UnjdD95anb0",
        "outputId": "bc050e95-d036-43f5-922c-c72b9862450a"
      },
      "source": [
        "scores = f_ratio_measure(x, y)\n",
        "scores1 = pearson_corr(x, y)\n",
        "\n",
        "print(scores)\n",
        "print(scores1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.50024701e-06  5.98707089e-02  3.75672252e-02  2.85949011e-02\n",
            "  1.21332075e-01  8.78646628e-05  2.35860735e-04  9.36791808e-02\n",
            "  7.94103039e-02  3.64109122e-03  5.31752688e-01  5.31177770e-03\n",
            "  3.47193763e-02  5.84321414e-02  2.86091784e-04  7.21970517e-02\n",
            "  2.14603243e-01  1.50273045e-02  1.29798086e-02 -1.94775158e-01\n",
            "  1.26326801e-02  3.38111931e-02  6.96692459e-03  2.01057823e-02\n",
            "  9.76955793e-02  3.90330239e-05  1.57032046e-02  2.56844714e-02\n",
            " -7.54249090e+00  8.30045874e-02  1.02740700e-02  2.21877041e-02\n",
            "  7.42942079e-02  5.16333627e-02  2.16513870e-02  3.62988364e-02\n",
            "  1.57398881e-02  5.88910672e-02  2.21966842e-03  1.23451490e-02\n",
            "  5.88910672e-02  6.96692459e-03  5.84321414e-02  2.01057823e-02\n",
            "  5.31752688e-01  3.47193763e-02  2.01057823e-02  7.21970517e-02\n",
            "  2.86091784e-04  1.29798086e-02  3.46043793e-03  9.50682959e-05\n",
            "  1.05103227e-03  4.58848616e-04  7.25822850e-05  2.84942941e-06\n",
            "  8.95388466e-03  5.99105069e-05  1.08656529e-03  2.27601760e-05\n",
            " -6.71958462e-05  3.16850975e-04  1.52929640e-04  1.57979174e-03\n",
            "  4.38816193e-04  1.48115582e-03  2.69973414e-03  4.50985841e-04\n",
            "  1.66900610e-03  2.48424945e-05  1.53453529e-03  1.14093733e-05\n",
            "  4.95235745e-04  8.36317156e-05  7.02267141e-04  1.67939612e-04\n",
            "  1.54842157e-04  1.16849235e-03  1.65367892e-03  7.82703328e-04\n",
            "  2.51330654e-04  2.96801675e-04  3.61317524e-03  9.87736504e-04\n",
            "  6.82000339e-03  3.14694266e-05  2.22168273e-04  1.21433828e-04\n",
            "  9.22520886e-04  3.70960796e-03  2.66398360e-04  1.63300680e-03\n",
            "  1.16716277e-03  3.36510098e-05  1.46836684e-03  1.81809172e-05\n",
            "  5.52774867e-05  1.17382729e-04  8.62962635e-04  2.11016944e-04]\n",
            "[-0.00265108 -0.24359127 -0.54943336  0.16219484 -0.26289579  0.0095461\n",
            "  0.01535019  0.27919265 -0.25902596 -0.06018696  0.31619308 -0.07517514\n",
            "  0.3478542  -0.21695377 -0.01688892 -0.22323165 -0.37876391 -0.11946196\n",
            "  0.12440711  0.15009469 -0.11711423 -0.18918093 -0.08748507  0.13770628\n",
            " -0.34056944  0.00613522 -0.12298906  0.14744943 -0.34361164 -0.32396294\n",
            " -0.10241636  0.17805236  0.32036758  0.2209985   0.14012027 -0.19138306\n",
            " -0.12255322  0.2463271  -0.13536303  0.1151254   0.2463271  -0.08748507\n",
            " -0.21695377  0.13770628  0.31619308  0.3478542   0.13770628 -0.22323165\n",
            " -0.01688892  0.12440711 -0.05810156  0.00931198  0.03358464 -0.02297385\n",
            "  0.00817032 -0.00155302  0.08846761  0.00793023 -0.02933962  0.00493681\n",
            " -0.00295719 -0.02115001 -0.01273185  0.03400815 -0.01101654  0.03893955\n",
            "  0.05377414  0.01987922  0.03712804  0.00510763  0.03962461  0.00320518\n",
            " -0.02197292  0.00890202 -0.02575752 -0.01676197 -0.01648447 -0.03266956\n",
            "  0.04379082  0.02463186 -0.01690537 -0.01673916  0.05185242 -0.03149726\n",
            "  0.07907625  0.00597445  0.01507479  0.0115684  -0.02886418  0.06082789\n",
            " -0.01591817 -0.04278767  0.0286762  -0.00524261 -0.03786685  0.00370704\n",
            "  0.00762318 -0.01368092 -0.02419583  0.01535253]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKhRGVHb0hM"
      },
      "source": [
        "# Cutting rules for univariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN1khlDmem0_"
      },
      "source": [
        "1. filters.univariate.**select_best_by_value**(value)\t\n",
        "2. filters.univariate.**select_worst_by_value**(value)\t\n",
        "3. filters.univariate.**select_k_best**(k)\t\n",
        "4. filters.univariate.**select_k_worst**(k)\t\n",
        "5. filters.univariate.**select_best_percentage**(percent)\t\n",
        "6. filters.univariate.**select_worst_percentage**(percent)\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJdNjdxKaBCT",
        "outputId": "bc3b01d9-41b7-4001-d0f4-7cd4c35b2b14"
      },
      "source": [
        "ufilterBest = UnivariateFilter(f_ratio_measure, select_k_best(10))\n",
        "ufilterBest.fit(x, y)\n",
        "\n",
        "ufilterBestPercentage= UnivariateFilter(f_ratio_measure, select_best_percentage(0.1))\n",
        "ufilterBestPercentage.fit(x, y)\n",
        "\n",
        "print(ufilterBest.selected_features)\n",
        "print(ufilterBestPercentage.selected_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 44, 16, 4, 24, 7, 29, 8, 32, 15]\n",
            "[1, 4, 7, 8, 10, 13, 15, 16, 24, 29, 32, 37, 40, 42, 44, 47]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkdDyfEciWkK"
      },
      "source": [
        "# Multivariate filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARK_poX_kMmV"
      },
      "source": [
        "Доступны следующие фильтры\n",
        "1. filters.multivariate.**DISRWithMassive**([…]) - Creates DISR (Double Input Symmetric Relevance) feature selection filter based on kASSI criterion for feature selection which aims at maximizing the mutual information avoiding, meanwhile, large multivariate density estimation.\n",
        "2. filters.multivariate.**FCBFDiscreteFilter**() -\tCreates FCBF (Fast Correlation Based filter) feature selection filter based on mutual information criteria for data with discrete features This filter finds best set of features by searching for a feature, which provides the most information about classification problem on given dataset at each step and then eliminating features which are less relevant than redundant\n",
        "3. filters.multivariate.**STIR**([n_features_to_keep]) -\tFeature selection using STIR algorithm.\n",
        "4. filters.multivariate.**TraceRatioFisher**(…) -\tCreates TraceRatio(similarity based) feature selection filter performed in supervised way, i.e fisher version\n",
        "5. filters.multivariate.**MIMAGA**(mim_size, …)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_zLs-5bjqKP"
      },
      "source": [
        "Пример Double Input Symmetric Relevance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhreAlEjph6",
        "outputId": "dad2b7e1-2f72-4dd6-eee6-5a9b4571b505"
      },
      "source": [
        "X = np.array([[1, 2, 3, 3, 1],[2, 2, 3, 3, 2], [1, 3, 3, 1, 3],[3, 1, 3, 1, 4],[4, 4, 3, 1, 5]])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "disr = DISRWithMassive(3)\n",
        "print(disr.fit_transform(X, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 1]\n",
            " [2 2 2]\n",
            " [1 3 3]\n",
            " [3 1 4]\n",
            " [4 4 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ch0vpi9kot_"
      },
      "source": [
        "# Measures for multivariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po0jkk3AkuZC"
      },
      "source": [
        "1. filters.multivariate.**MIM**(selected_features, …)\t- Mutual Information Maximization feature scoring criterion.\n",
        "1. filters.multivariate.**MRMR**(selected_features, …)\t- Minimum-Redundancy Maximum-Relevance feature scoring criterion.\n",
        "1. filters.multivariate.**JMI**(selected_features, …)\t- Joint Mutual Information feature scoring criterion.\n",
        "1. filters.multivariate.**CIFE**(selected_features, …)\t- Conditional Infomax Feature Extraction feature scoring criterion.\n",
        "1. filters.multivariate.**MIFS**(selected_features, …)\t- Mutual Information Feature Selection feature scoring criterion.\n",
        "1. filters.multivariate.**CMIM**(selected_features, …)\t- Conditional Mutual Info Maximisation feature scoring criterion.\n",
        "1. filters.multivariate.**ICAP**(selected_features, …)\t- Interaction Capping feature scoring criterion.\n",
        "1. filters.multivariate.**DCSF**(selected_features, …)\t- Dynamic change of selected feature with the class scoring criterion.\n",
        "1. filters.multivariate.**CFR**(selected_features, …)\t- The criterion of CFR maximizes the correlation and minimizes the redundancy.\n",
        "1. filters.multivariate.**MRI**(selected_features, …)\t- Max-Relevance and Max-Independence feature scoring criteria.\n",
        "1. filters.multivariate.**IWFS**(selected_features, …)\t- Interaction Weight base feature scoring criteria.\n",
        "1. filters.multivariate.**generalizedCriteria**(…)\t- This feature scoring criteria is a linear combination of all relevance, redundancy, conditional dependency Given set of already selected features and set of remaining features on dataset X with labels y selects next feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha7oNJy6lAej"
      },
      "source": [
        "Пример использования Minimum-Redundancy Maximum-Relevance (MRMR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmxoDaXJiW6m",
        "outputId": "80952c30-6272-4df8-9a4d-74dfa3dddd5b"
      },
      "source": [
        "est = KBinsDiscretizer(n_bins=10, encode='ordinal')\n",
        "data, target = np.array(x), np.array(y)\n",
        "est.fit(data)\n",
        "data = est.transform(data)\n",
        "selected_features = [1, 2]\n",
        "other_features = [i for i in range(0, data.shape[1]) if i not in selected_features]\n",
        "print(MRMR(np.array(selected_features), np.array(other_features), data, target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.53276006 1.56352214 1.55033043 1.5330381  1.50815535 1.47297681\n",
            " 1.54920536 1.53577961 1.43720227 1.51865242 1.37121041 1.5289223\n",
            " 1.47436127 1.55123743 1.43636821 1.489084   1.53647548 1.44995846\n",
            " 1.51818786 1.52063921 1.50695557 1.45168611 1.47330795 1.52711876\n",
            " 1.52640082 1.40560296 1.48971165 1.47460487 1.52738426 1.47556102\n",
            " 1.54265934 1.50515313 1.51906161 1.51936605 1.54824853 1.49396177\n",
            " 1.5334391  1.51559093 1.49396177 1.50695557 1.5289223  1.45168611\n",
            " 1.43720227 1.37121041 1.45168611 1.55123743 1.47436127 1.53647548\n",
            " 1.57790373 1.56887104 1.56863816 1.57165131 1.57262151 1.56497928\n",
            " 1.56214768 1.56393325 1.55838476 1.56176975 1.56334919 1.56745668\n",
            " 1.56927942 1.57077596 1.558682   1.56509763 1.57278011 1.57417911\n",
            " 1.56458115 1.55505381 1.56801531 1.56522283 1.57152835 1.56949361\n",
            " 1.56836173 1.56443064 1.56655052 1.56924773 1.56305922 1.55974498\n",
            " 1.5637315  1.56897638 1.55764314 1.56206953 1.56823439 1.57043783\n",
            " 1.56365045 1.56340376 1.56822181 1.56967739 1.56940219 1.57079593\n",
            " 1.5635744  1.56819652 1.57357917 1.56772816 1.56892636 1.56596535\n",
            " 1.56149251 1.57189471]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgLXKYXylmem"
      },
      "source": [
        "# Unsupervised filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjeydSdUltWw"
      },
      "source": [
        "Пример TraceRatio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUJ2hBuclRuh",
        "outputId": "3e98d3b7-06e1-497b-83ee-9299d19dae94"
      },
      "source": [
        "tracer = TraceRatioLaplacian(10)\n",
        "print(tracer.run(x, y)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20 47 15 28  1  2 89 46 43 23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeBriAIMlxOK"
      },
      "source": [
        "# Sparse filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddvLxZZxl08b"
      },
      "source": [
        "1. filters.sparse.**MCFS**(d[, k, p, scheme, sigma]) -\tPerforms the Unsupervised Feature Selection for Multi-Cluster Data algorithm.\n",
        "1. filters.sparse.**NDFS**(p[, c, k, alpha, beta, …]) -\tPerforms the Nonnegative Discriminative Feature Selection algorithm.\n",
        "1. filters.sparse.**RFS**(p[, gamma, …])\t- Performs the Robust Feature Selection via Joint L2,1-Norms Minimization algorithm.\n",
        "1. filters.sparse.**SPEC**(p[, k, gamma, sigma, …]) -\tPerforms the Spectral Feature Selection algorithm.\n",
        "1. filters.sparse.**UDFS**(p[, c, k, gamma, l, …]) -\tPerforms the Unsupervised Discriminative Feature Selection algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918QZZbgmI-Q"
      },
      "source": [
        "# Ensemble methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQn7lSL4mspS"
      },
      "source": [
        "1. ensembles.measure_based.**WeightBased**(filters)\n",
        "1. ensembles.model_based.**BestSum**(models, …)\n",
        "1. ensembles.ranking_based.**Mixed**(filters) - Performs feature selection based on several filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGe36IU7eBdp"
      },
      "source": [
        "**Метод Mixed** - выполняет выбор признаков на основе нескольких фильтров, следующим образом: Получает ранги по каждому фильтру из входных данных. Проходит цикл, на каждой итерации = i выбирает признаки в позиции i в каждом фильтре, перемешивает их, затем добавляет в список результатов без дублирования, и продолжает до указанного количества признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXzce2EBnCCC"
      },
      "source": [
        "# Embedded methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_TBKB2nDf3"
      },
      "source": [
        "1. embedded.**MOS**([model, loss, seed])\t- Performs Minimizing Overlapping Selection under SMOTE (MOSS) or under No-Sampling (MOSNS) algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keym-0L9nLcX"
      },
      "source": [
        "# Hybrid methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj17awItnOKz"
      },
      "source": [
        "1. hybrid.**FilterWrapperHybrid**(filter_, wrapper)\t\n",
        "1. hybrid.**Melif**(filter_ensemble[, scorer, verbose])\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-UqS0hVnVKj"
      },
      "source": [
        "# Wrapper methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykLAXONqnX45"
      },
      "source": [
        "1. wrappers.deterministic.**AddDelWrapper**(…[, …])\t- Creates add-del feature wrapper\n",
        "1. wrappers.deterministic.**BackwardSelection**(…)\t- Backward Selection removes one feature at a time until the number of features to be removed is reached.\n",
        "1. wrappers.deterministic.**RecursiveElimination**(…)\t- Performs a recursive feature elimination until the required number of features is reached.\n",
        "1. wrappers.deterministic.**SequentialForwardSelection**(…)\t- Sequentially Adds Features that Maximises the Classifying function when combined with the features already used TODO add theory about this method\n",
        "1. wrappers.deterministic.**qpfs_wrapper**(X, y, alpha)\t- Performs Quadratic Programming Feature Selection algorithm.\n",
        "1. wrappers.randomized.**HillClimbingWrapper**(…)\t\n",
        "1. wrappers.randomized.**SimulatedAnnealing**(…)\t- Performs feature selection using simulated annealing\n",
        "1. wrappers.randomized.**TPhMGWO**([wolfNumber, …])\t- Performs Grey Wolf optimization with Two-Phase Mutation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoxYiJMbrk9-"
      },
      "source": [
        "Пример работы [Backward Selection](https://itmo-fs.readthedocs.io/en/latest/generated/ITMO_FS.wrappers.deterministic.BackwardSelection.html?highlight=wrappers.deterministic.BackwardSelection) - алгоритм убирает по одному параметру, пока число убранных параметров не достигнет заданного. Возвращает имена оставшихся параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4AILPC4r1f8",
        "outputId": "9ac2bdd8-3f44-4396-ae35-db35342816b6"
      },
      "source": [
        "from ITMO_FS.wrappers import BackwardSelection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x, y = make_classification(n_samples=100, n_features=20, n_informative=4, n_redundant=0, shuffle=False)\n",
        "data, target = np.array(x), np.array(y)\n",
        "\n",
        "model = BackwardSelection(LogisticRegression(), 15, 'f1_macro')\n",
        "model.fit(data, target)\n",
        "print(model.selected_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  4  7 10 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N33x_MZlgK66"
      },
      "source": [
        "**RecursiveElimination** - выполняет рекурсивное исключение признаков, пока не будет достигнуто необходимое количество признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbdIkKydpey"
      },
      "source": [
        "**SimulatedAnnealing** - выполняет выбор признаков с помощью имитации отжига. Алгоритм имитации отжига - это метод решения моделей параметров оптимизации с ограничениями и без ограничений. Метод основан на физическом отжиге и используется для минимизации энергии системы.\n",
        "\n",
        "Параметры:\n",
        "\n",
        "*   seed (integer) - случайное начальное число, используемое для инициализации np.random.seed ()\n",
        "*   iteration_number (integer) - количество итераций алгоритма\n",
        "*   classifier (Classifier instance) - классификатор, используемый для обучения и тестирования предоставленных наборов данных.\n",
        "*   c (целое число) - константа c используется для управления скоростью пертурбации признаков\n",
        "*   init_number_of_features (float) - количество признаков для инициализации подмножества начальных признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUZvoUn8c7GZ"
      },
      "source": [
        "**SequentialForwardSelection** - последовательно добавляет признаки, которые максимизируют функцию классификации в сочетании с уже используемыми признаками. То есть, признаки последовательно добавляются к пустому набору функций до тех пор, пока добавление дополнительных функций не уменьшит критерий.\n",
        "\n",
        "Параметры:\n",
        "\n",
        "*   Estimator (object) - оценщик контролируемого обучения с методом подбора, который предоставляет информацию о важности признака либо через атрибут coef_, либо через атрибут feature_importances_.\n",
        "*   n_features (int) - количество признаков для выбора.\n",
        "*   measure (string or callable) – стандартная метрика оценки (например, «f1» или «roc_auc») или вызываемый объект / функция с мерой сигнатуры (estimator, x, y), которая должна возвращать только одно значение.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVueemJwc_qq"
      },
      "source": [
        "Пример SequentialForwardSelection:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p5B3CF9dFS5",
        "outputId": "dcbe99cc-0127-4c51-816b-10844be04b36"
      },
      "source": [
        "from ITMO_FS.wrappers import SequentialForwardSelection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "dataset = make_classification(n_samples=100, n_features=20, n_informative=4, n_redundant=0, shuffle=False)\n",
        "data, target = np.array(dataset[0]), np.array(dataset[1])\n",
        "model = SequentialForwardSelection(LogisticRegression(), 5, 'f1_macro')\n",
        "model.fit(data, target)\n",
        "print(model.selected_features)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4  6  8  3 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HfZ_losnsRi"
      },
      "source": [
        "# Источники\n",
        "Описание API - https://itmo-fs.readthedocs.io/en/latest/api.html  \n",
        "Статья на хабре - https://habr.com/ru/company/spbifmo/blog/516194/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-0uhVlzt0GT"
      },
      "source": [
        "# Ревью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQq9KdCst3Q6"
      },
      "source": [
        "## Передреев Дмитрий\n",
        "\n",
        "Туториал прошел. Если запускать все блоки кода по порядку, выдавалась ошибка, т.к. во втором блоке мы определяли x, y\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x, y = make_classification(1000, 100, n_informative = 10, n_redundant = 30, n_repeated = 10, shuffle = False)\n",
        "```\n",
        "\n",
        "а в третьем перезаписывали эти значения для демонстрации VDM.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x = np.array([[0, 0, 0, 0],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 0, 0, 2]])\n",
        "y = np.array([0,\n",
        "              1,\n",
        "              1])\n",
        "```\n",
        "\n",
        "Тогда зависящие от изначально заданных x, y блоки падали с ошибкой размерности. Пофиксил.\n",
        "\n",
        "Добавил короткое описание VDM и пример Backward Selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwdZGpTYJ8Qv"
      },
      "source": [
        "# Ревью (Мамашев Завур)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLogVF_UKAYw"
      },
      "source": [
        "За исключением нюанса указанного в ревью у Дмитрия Передреева, туториал успешно пройден. Добавляю описания и примеры некоторых методов (Mixed(filters), SequentialForwardSelection, SimulatedAnnealing, RecursiveElimination). \n",
        "\n"
      ]
    }
  ]
}