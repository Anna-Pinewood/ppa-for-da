{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natasha.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mash1negun/ppa-for-da/blob/AddingFile/students/%D0%9C%D0%B0%D0%BC%D0%B0%D1%88%D0%B5%D0%B2_%D0%97%D0%B0%D0%B2%D1%83%D1%80/Natasha(%D0%A0%D0%B5%D0%B2%D1%8C%D1%8E%20%D0%BD%D0%B0%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%83%20%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D1%8F%20%D0%A1%D1%82%D1%80%D0%BE%D0%BA%D0%BE%D0%B2%D0%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmY3skSUM6o8"
      },
      "source": [
        "# Предобработка текстовых данных с помощью фреймворка Natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esDsQB0cvmBM"
      },
      "source": [
        "Natasha решает базовые задачи NLP (natural language processing) для русского языка: токенизация, сегментация предложений, встраивание слов, морфология, лемматизация, нормализация фраз, синтаксический анализ, работа с NER, извлечение фактов. \n",
        "\n",
        "[Natasha](https://natasha.github.io/ner/) объединяет библиотеки проекта Natasha под одним удобным API:\n",
        "\n",
        "* [Razdel](https://natasha.github.io/razdel/) - токенизация, сегментация предложений для русского языка\n",
        "\n",
        "* [Navec](https://natasha.github.io/navec/) - вектора русских слов\n",
        "\n",
        "* [Slovnet](https://github.com/natasha/slovnet) - библиотека с методами глубокого обучения для русского NLP, компактные модели для русской морфологии, синтаксиса и NER.\n",
        "\n",
        "* [Yargy](https://github.com/natasha/yargy) - извлечение фактов на основе правил, аналогичное синтаксическому анализатору Tomita.\n",
        "\n",
        "Рассмотрим примеры использования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEVp8ulQplGO",
        "outputId": "506ee21c-8fc3-4199-bb06-8e8c89ef7d57"
      },
      "source": [
        " !pip install natasha"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM4FX4IaqhKv"
      },
      "source": [
        "from natasha import (\n",
        "    DatesExtractor,\n",
        "    MoneyExtractor,\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "    AddrExtractor,\n",
        "\n",
        "    Doc\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqLHCMrxqnSI"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "\n",
        "addr_extractor = AddrExtractor(morph_vocab)\n",
        "dates_extractor = DatesExtractor(morph_vocab)\n",
        "money_extractor = MoneyExtractor(morph_vocab)\n",
        "names_extractor = NamesExtractor(morph_vocab)\n",
        "\n",
        "text = '''Студенты и сотрудники лаборатории Машинного обучения Университета ИТМО разработали библиотеку для Python, которая решает ключевую задачу машинного обучения.\n",
        "\n",
        "Расскажем, почему появился этот инструмент и что он умеет.\n",
        "Нехватка алгоритмов\n",
        "\n",
        "Одна из ключевых задач машинного обучения — снижение размерности данных. Дата-саентисты сокращают число переменных, вычленяя среди них значения, наибольшим образом влияющие на результат. После этой операции модель машинного обучения требует меньше памяти, работает быстрее и качественнее. Пример ниже показывает, что исключение дублирующих признаков увеличивает точность классификации с 0,903 до 0,943.\n",
        "\n",
        "Существует два подхода к уменьшению размерности — конструирование и выбор признаков. В областях вроде биоинформатики и медицины чаще используют последний, так как он позволяет выделить значимые признаки с сохранением семантики, то есть не меняет исходный смысл признаков. Однако в самых распространенных библиотеках машинного обучения на Python — scikit-learn, pytorch, keras, tensorflow — нет полноценного набора методов выбора признаков.\n",
        "\n",
        "Для решения этой проблемы студенты и аспиранты Университета ИТМО разработали открытую библиотеку — ITMO_FS. Над ней трудится команда под руководством Ивана Сметанникова, доцента факультета информационных технологий и программирования, заместителя заведующего лабораторией Машинного обучения. Ведущий разработчик — Никита Пильненьский, закончивший магистратуру «Машинное обучение и анализ данных». Теперь он поступает в аспирантуру.\n",
        "\n",
        "«За последние несколько лет в нашу лабораторию приходили запросы на решение задач, для которых не подходил стандартный инструментарий. Например, нам требовались ансамблирующие алгоритмы на основе объединения фильтров, или алгоритмы, учитывающие наличие заранее известных (экспертно-размеченных) значимых признаков.\n",
        "\n",
        "Посмотрев на существующие решения, мы пришли к выводу, что они не только не содержат необходимые нам инструменты, но и не являются достаточно гибкими для их возможной мягкой интеграции. В контексте того, что среди таких библиотек конкуренция слаба, мы решили сделать свою библиотеку, исправляющую большинство недостатков».\n",
        "\n",
        "— Иван Сметанников\n",
        "'''\n",
        "doc = Doc(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocdnCUWXrD5z"
      },
      "source": [
        "# Разделение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLQeWiTrIK8"
      },
      "source": [
        "После сегментации можно работать как с отдельными токенами, так и с целыми предложениями (которые в себе также содержат токены)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWiFLPcqtDp",
        "outputId": "0b75f975-54e5-4f80-a66e-b04740277492"
      },
      "source": [
        "doc.segment(segmenter)\n",
        "print(doc.tokens[:5])\n",
        "print(doc.sents[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocToken(stop=8, text='Студенты'), DocToken(start=9, stop=10, text='и'), DocToken(start=11, stop=21, text='сотрудники'), DocToken(start=22, stop=33, text='лаборатории'), DocToken(start=34, stop=43, text='Машинного')]\n",
            "[DocSent(stop=156, text='Студенты и сотрудники лаборатории Машинного обуче..., tokens=[...]), DocSent(start=158, stop=216, text='Расскажем, почему появился этот инструмент и что ..., tokens=[...]), DocSent(start=217, stop=310, text='Нехватка алгоритмов\\n\\nОдна из ключевых задач маш..., tokens=[...]), DocSent(start=311, stop=424, text='Дата-саентисты сокращают число переменных, вычлен..., tokens=[...]), DocSent(start=425, stop=526, text='После этой операции модель машинного обучения тре..., tokens=[...])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1pYrG_0rglP"
      },
      "source": [
        "# Морфология"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMMpCQzTrit_"
      },
      "source": [
        "Библиотека умеет проводить морфологический анализ, можно работать снова с каждым токеном. Также уже есть встроенный \"красивый\" вывод признаков\n",
        "\n",
        "Зависит от шага с разделением и дополняет уже существующую информацию о токенах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2q2v7hyrjeA",
        "outputId": "5f4ee9d4-860b-4f0d-9d36-53bd29e2e1a7"
      },
      "source": [
        "doc.tag_morph(morph_tagger)\n",
        "print(doc.tokens[:5])\n",
        "doc.sents[0].morph.print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocToken(stop=8, text='Студенты', pos='NOUN', feats=<Anim,Nom,Masc,Plur>), DocToken(start=9, stop=10, text='и', pos='CCONJ'), DocToken(start=11, stop=21, text='сотрудники', pos='NOUN', feats=<Anim,Nom,Masc,Plur>), DocToken(start=22, stop=33, text='лаборатории', pos='NOUN', feats=<Inan,Gen,Fem,Sing>), DocToken(start=34, stop=43, text='Машинного', pos='ADJ', feats=<Gen,Pos,Neut,Sing>)]\n",
            "            Студенты NOUN,Animacy=Anim,Case=Nom,Gender=Masc,Number=Plur\n",
            "                   и CCONJ\n",
            "          сотрудники NOUN,Animacy=Anim,Case=Nom,Gender=Masc,Number=Plur\n",
            "         лаборатории NOUN,Animacy=Inan,Case=Gen,Gender=Fem,Number=Sing\n",
            "           Машинного ADJ,Case=Gen,Degree=Pos,Gender=Neut,Number=Sing\n",
            "            обучения NOUN,Animacy=Inan,Case=Gen,Gender=Neut,Number=Sing\n",
            "        Университета PROPN,Animacy=Inan,Case=Gen,Gender=Masc,Number=Sing\n",
            "                ИТМО PROPN,Animacy=Inan,Case=Gen,Gender=Masc,Number=Sing\n",
            "         разработали VERB,Aspect=Perf,Mood=Ind,Number=Plur,Tense=Past,VerbForm=Fin,Voice=Act\n",
            "          библиотеку NOUN,Animacy=Inan,Case=Acc,Gender=Fem,Number=Sing\n",
            "                 для ADP\n",
            "              Python PROPN,Foreign=Yes\n",
            "                   , PUNCT\n",
            "             которая PRON,Case=Nom,Gender=Fem,Number=Sing\n",
            "              решает VERB,Aspect=Imp,Mood=Ind,Number=Sing,Person=3,Tense=Pres,VerbForm=Fin,Voice=Act\n",
            "            ключевую ADJ,Case=Acc,Degree=Pos,Gender=Fem,Number=Sing\n",
            "              задачу NOUN,Animacy=Inan,Case=Acc,Gender=Fem,Number=Sing\n",
            "           машинного ADJ,Case=Gen,Degree=Pos,Gender=Neut,Number=Sing\n",
            "            обучения NOUN,Animacy=Inan,Case=Gen,Gender=Neut,Number=Sing\n",
            "                   . PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_DLAal4sJFO"
      },
      "source": [
        "# Лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Roov1qssfo_"
      },
      "source": [
        "Зависит от шага с морфологическим разбором и дополняет уже существующую информацию о токенах\n",
        "\n",
        "Выведем первые 15 примеров приведения слова к его нормальной форме"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxrJaGuxspNo",
        "outputId": "c0ff90e9-c375-48b0-cfa1-06547810071e"
      },
      "source": [
        "for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "    \n",
        "print(doc.tokens[:5])\n",
        "{_.text: _.lemma for _ in doc.tokens[:15]}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocToken(stop=8, text='Студенты', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='студент'), DocToken(start=9, stop=10, text='и', pos='CCONJ', lemma='и'), DocToken(start=11, stop=21, text='сотрудники', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='сотрудник'), DocToken(start=22, stop=33, text='лаборатории', pos='NOUN', feats=<Inan,Gen,Fem,Sing>, lemma='лаборатория'), DocToken(start=34, stop=43, text='Машинного', pos='ADJ', feats=<Gen,Pos,Neut,Sing>, lemma='машинный')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " 'Python': 'python',\n",
              " 'ИТМО': 'итмо',\n",
              " 'Машинного': 'машинный',\n",
              " 'Студенты': 'студент',\n",
              " 'Университета': 'университет',\n",
              " 'библиотеку': 'библиотека',\n",
              " 'для': 'для',\n",
              " 'и': 'и',\n",
              " 'которая': 'который',\n",
              " 'лаборатории': 'лаборатория',\n",
              " 'обучения': 'обучение',\n",
              " 'разработали': 'разработать',\n",
              " 'решает': 'решать',\n",
              " 'сотрудники': 'сотрудник'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8bMbIWtgUa"
      },
      "source": [
        "# Синтаксический разбор"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBbJIZiytj0g"
      },
      "source": [
        "Зависит от шага с разделением на токены, а именно использует информацию о предложениях"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG0PwdXqts7O",
        "outputId": "3051897f-d0de-4972-8d11-95d558ddda26"
      },
      "source": [
        "doc.parse_syntax(syntax_parser)\n",
        "print(doc.tokens[:5])\n",
        "doc.sents[0].syntax.print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocToken(stop=8, text='Студенты', id='1_1', head_id='1_9', rel='nsubj', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='студент'), DocToken(start=9, stop=10, text='и', id='1_2', head_id='1_3', rel='cc', pos='CCONJ', lemma='и'), DocToken(start=11, stop=21, text='сотрудники', id='1_3', head_id='1_1', rel='conj', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='сотрудник'), DocToken(start=22, stop=33, text='лаборатории', id='1_4', head_id='1_3', rel='nmod', pos='NOUN', feats=<Inan,Gen,Fem,Sing>, lemma='лаборатория'), DocToken(start=34, stop=43, text='Машинного', id='1_5', head_id='1_6', rel='amod', pos='ADJ', feats=<Gen,Pos,Neut,Sing>, lemma='машинный')]\n",
            "  ┌────────► Студенты     nsubj\n",
            "  │       ┌► и            cc\n",
            "  │     ┌─└─ сотрудники   \n",
            "  │ ┌─┌─└──► лаборатории  nmod\n",
            "  │ │ │   ┌► Машинного    amod\n",
            "  │ │ └──►└─ обучения     nmod\n",
            "  │ └────►┌─ Университета nmod\n",
            "  │       └► ИТМО         nmod\n",
            "┌─└───────┌─ разработали  \n",
            "│     ┌─┌─└► библиотеку   obj\n",
            "│     │ │ ┌► для          case\n",
            "│     │ └►└─ Python       nmod\n",
            "│     │ ┌──► ,            punct\n",
            "│     │ │ ┌► которая      nsubj\n",
            "│     └►└─└─ решает       acl:relcl\n",
            "│     │   ┌► ключевую     amod\n",
            "│   ┌─└──►└─ задачу       obj\n",
            "│   │     ┌► машинного    amod\n",
            "│   └────►└─ обучения     nmod\n",
            "└──────────► .            punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b_g6txAt1nl"
      },
      "source": [
        "# Распознование именованных сущностей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlNi5eFnt4tE"
      },
      "source": [
        "Зависит от шага с разделением на токены"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5NwlP6LuB6m",
        "outputId": "068bc399-09ef-4ac0-ac86-57692f99b930"
      },
      "source": [
        "doc.tag_ner(ner_tagger)\n",
        "print(doc.spans[:5])\n",
        "doc.ner.print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...]), DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...]), DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...]), DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...]), DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...])]\n",
            "Студенты и сотрудники лаборатории Машинного обучения Университета ИТМО\n",
            "                                  ORG─────────────── ORG──────────────\n",
            " разработали библиотеку для Python, которая решает ключевую задачу \n",
            "машинного обучения.\n",
            "Расскажем, почему появился этот инструмент и что он умеет.\n",
            "Нехватка алгоритмов\n",
            "Одна из ключевых задач машинного обучения — снижение размерности \n",
            "данных. Дата-саентисты сокращают число переменных, вычленяя среди них \n",
            "значения, наибольшим образом влияющие на результат. После этой \n",
            "операции модель машинного обучения требует меньше памяти, работает \n",
            "быстрее и качественнее. Пример ниже показывает, что исключение \n",
            "дублирующих признаков увеличивает точность классификации с 0,903 до \n",
            "0,943.\n",
            "Существует два подхода к уменьшению размерности — конструирование и \n",
            "выбор признаков. В областях вроде биоинформатики и медицины чаще \n",
            "используют последний, так как он позволяет выделить значимые признаки \n",
            "с сохранением семантики, то есть не меняет исходный смысл признаков. \n",
            "Однако в самых распространенных библиотеках машинного обучения на \n",
            "Python — scikit-learn, pytorch, keras, tensorflow — нет полноценного \n",
            "набора методов выбора признаков.\n",
            "Для решения этой проблемы студенты и аспиранты Университета ИТМО \n",
            "                                               ORG────────────── \n",
            "разработали открытую библиотеку — ITMO_FS. Над ней трудится команда \n",
            "под руководством Ивана Сметанникова, доцента факультета информационных\n",
            "                 PER───────────────                                   \n",
            " технологий и программирования, заместителя заведующего лабораторией \n",
            "Машинного обучения. Ведущий разработчик — Никита Пильненьский, \n",
            "ORG───────────────                        PER────────────────  \n",
            "закончивший магистратуру «Машинное обучение и анализ данных». Теперь \n",
            "он поступает в аспирантуру.\n",
            "«За последние несколько лет в нашу лабораторию приходили запросы на \n",
            "решение задач, для которых не подходил стандартный инструментарий. \n",
            "Например, нам требовались ансамблирующие алгоритмы на основе \n",
            "объединения фильтров, или алгоритмы, учитывающие наличие заранее \n",
            "известных (экспертно-размеченных) значимых признаков.\n",
            "Посмотрев на существующие решения, мы пришли к выводу, что они не \n",
            "только не содержат необходимые нам инструменты, но и не являются \n",
            "достаточно гибкими для их возможной мягкой интеграции. В контексте \n",
            "того, что среди таких библиотек конкуренция слаба, мы решили сделать \n",
            "свою библиотеку, исправляющую большинство недостатков».\n",
            "— Иван Сметанников\n",
            "  PER─────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzVMqHm7uOT1"
      },
      "source": [
        "Затем такие сущности можно нормализовать\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMtsX3VEuSZQ",
        "outputId": "3fcc5726-198e-42af-88ad-21fde077313d"
      },
      "source": [
        "for span in doc.spans:\n",
        "   span.normalize(morph_vocab)\n",
        "print(doc.spans[:5])\n",
        "{_.text: _.normal for _ in doc.spans if _.text != _.normal}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинное обучение'), DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университет ИТМО'), DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университет ИТМО'), DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...], normal='Иван Сметанников'), DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинное обучение')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ивана Сметанникова': 'Иван Сметанников',\n",
              " 'Машинного обучения': 'Машинное обучение',\n",
              " 'Университета ИТМО': 'Университет ИТМО'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiG6UODBubvP"
      },
      "source": [
        "А также рзделить на составные чати (имя, фамилия и тд)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwEtYGQzuhCe",
        "outputId": "42308fd9-30e7-4fdb-b365-9eae50e0c359"
      },
      "source": [
        "for span in doc.spans:\n",
        "   if span.type == PER:\n",
        "       span.extract_fact(names_extractor)\n",
        "\n",
        "print(doc.spans[:5])\n",
        "{_.normal: _.fact.as_dict for _ in doc.spans if _.type == PER}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинное обучение'), DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университет ИТМО'), DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университет ИТМО'), DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...], normal='Иван Сметанников', fact=DocFact(slots=[...])), DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинное обучение')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Иван Сметанников': {'first': 'Иван', 'last': 'Сметанников'},\n",
              " 'Никита Пильненьский': {'first': 'Никита', 'last': 'Пильненьский'}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkCFkpcS54r"
      },
      "source": [
        "# Извлечение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwU4un8RTNmk"
      },
      "source": [
        "В дополнение к names_extractor, Natasha связывает несколько других экстракторов: date_extractor, money_extractor и addr_extractor. Все экстракторы основаны на Yargy-parser, что означает, что они корректно работают только с небольшим предопределенным набором текстов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lfci8oaTlXt"
      },
      "source": [
        "**DatesExtractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n43mJIeiTng2",
        "outputId": "ffbe73e2-9e2c-4096-b361-ab7998e07d7e"
      },
      "source": [
        "text = '24.01.2017, 2015 год, 2014 г, 1 апреля, май 2017 г., 9 мая 2017 года'\n",
        "list(dates_extractor(text))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Match(\n",
              "     start=0,\n",
              "     stop=10,\n",
              "     fact=Date(\n",
              "         year=2017,\n",
              "         month=1,\n",
              "         day=24\n",
              "     )\n",
              " ), Match(\n",
              "     start=12,\n",
              "     stop=20,\n",
              "     fact=Date(\n",
              "         year=2015,\n",
              "         month=None,\n",
              "         day=None\n",
              "     )\n",
              " ), Match(\n",
              "     start=22,\n",
              "     stop=28,\n",
              "     fact=Date(\n",
              "         year=2014,\n",
              "         month=None,\n",
              "         day=None\n",
              "     )\n",
              " ), Match(\n",
              "     start=30,\n",
              "     stop=38,\n",
              "     fact=Date(\n",
              "         year=None,\n",
              "         month=4,\n",
              "         day=1\n",
              "     )\n",
              " ), Match(\n",
              "     start=40,\n",
              "     stop=51,\n",
              "     fact=Date(\n",
              "         year=2017,\n",
              "         month=5,\n",
              "         day=None\n",
              "     )\n",
              " ), Match(\n",
              "     start=53,\n",
              "     stop=68,\n",
              "     fact=Date(\n",
              "         year=2017,\n",
              "         month=5,\n",
              "         day=9\n",
              "     )\n",
              " )]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh09tH5pW5el"
      },
      "source": [
        "**MoneyExtractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlcapZWKXABN",
        "outputId": "273d4746-11d3-459e-9569-4589a199f2c6"
      },
      "source": [
        "text = '1 599 059, 38 Евро, 420 долларов, 20 млн руб, 20 т. р., 881 913 (Восемьсот восемьдесят одна тысяча девятьсот тринадцать) руб. 98 коп.'\n",
        "list(money_extractor(text))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Match(\n",
              "     start=0,\n",
              "     stop=18,\n",
              "     fact=Money(\n",
              "         amount=1599059.38,\n",
              "         currency='EUR'\n",
              "     )\n",
              " ), Match(\n",
              "     start=20,\n",
              "     stop=32,\n",
              "     fact=Money(\n",
              "         amount=420,\n",
              "         currency='USD'\n",
              "     )\n",
              " ), Match(\n",
              "     start=34,\n",
              "     stop=44,\n",
              "     fact=Money(\n",
              "         amount=20000000,\n",
              "         currency='RUB'\n",
              "     )\n",
              " ), Match(\n",
              "     start=46,\n",
              "     stop=54,\n",
              "     fact=Money(\n",
              "         amount=20000,\n",
              "         currency='RUB'\n",
              "     )\n",
              " ), Match(\n",
              "     start=56,\n",
              "     stop=133,\n",
              "     fact=Money(\n",
              "         amount=881913.98,\n",
              "         currency='RUB'\n",
              "     )\n",
              " )]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Z_dcVFYBFv"
      },
      "source": [
        "**AddrExtractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "9e0gM5wMXLTD",
        "outputId": "0f99f03c-07c3-44ba-9e0c-4833eadb8f49"
      },
      "source": [
        "lines = [\n",
        "    'Россия, Вологодская обл. г. Череповец, пр.Победы 93 б',\n",
        "    '692909, РФ, Приморский край, г. Находка, ул. Добролюбова, 18',\n",
        "    'ул. Народного Ополчения д. 9к.3'\n",
        "]\n",
        "for line in lines:\n",
        "    display(addr_extractor.find(line))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Match(\n",
              "    start=0,\n",
              "    stop=48,\n",
              "    fact=Addr(\n",
              "        parts=[AddrPart(\n",
              "             value='Россия',\n",
              "             type='страна'\n",
              "         ), AddrPart(\n",
              "             value='Вологодская',\n",
              "             type='область'\n",
              "         ), AddrPart(\n",
              "             value='Череповец',\n",
              "             type='город'\n",
              "         ), AddrPart(\n",
              "             value='Победы',\n",
              "             type='проспект'\n",
              "         )]\n",
              "    )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Match(\n",
              "    start=0,\n",
              "    stop=56,\n",
              "    fact=Addr(\n",
              "        parts=[AddrPart(\n",
              "             value='692909',\n",
              "             type='индекс'\n",
              "         ), AddrPart(\n",
              "             value='РФ',\n",
              "             type='страна'\n",
              "         ), AddrPart(\n",
              "             value='Приморский',\n",
              "             type='край'\n",
              "         ), AddrPart(\n",
              "             value='Находка',\n",
              "             type='город'\n",
              "         ), AddrPart(\n",
              "             value='Добролюбова',\n",
              "             type='улица'\n",
              "         )]\n",
              "    )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Match(\n",
              "    start=0,\n",
              "    stop=29,\n",
              "    fact=Addr(\n",
              "        parts=[AddrPart(\n",
              "             value='Народного Ополчения',\n",
              "             type='улица'\n",
              "         ), AddrPart(\n",
              "             value='9к',\n",
              "             type='дом'\n",
              "         )]\n",
              "    )\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjsNtbOIK5J5"
      },
      "source": [
        "# Источники\n",
        "\n",
        "https://github.com/natasha\n",
        "\n",
        "https://natasha.github.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFfC8jrKK8PA"
      },
      "source": [
        "# Ревью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnPNcKg3LAxp"
      },
      "source": [
        "## Передреев Дмитрий\n",
        "\n",
        "Туториал прошел. Добавил заголовок и ссылки на документацию модулей проекта - в них более подробно разобраны примеры использования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZVgJov-Sdtx"
      },
      "source": [
        "# Ревью (Мамашев Завур)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZX81WaNSh5x"
      },
      "source": [
        "Туториал успешно пройден. Добавил примеры и описания (DatesExtractor, MoneyExtractor, AddrExtractor)."
      ]
    }
  ]
}