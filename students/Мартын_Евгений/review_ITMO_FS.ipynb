{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ITMO_FS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYmEi2rn9Z6U"
      },
      "source": [
        "ITMO_FS разработали студенты и сотрудники лаборатории Машинного обучения Университета ИТМО. Она реализована на Python и совместима со scikit-learn, которая де-факто считается основным инструментом анализа данных. Ее селекторы признаков принимают те же параметры:\n",
        "\n",
        "data: array-like (2-D list, pandas.Dataframe, numpy.array);  \n",
        "targets: array-like (1-D list, pandas.Series, numpy.array).\n",
        "\n",
        "Библиотека поддерживает все классические подходы к отбору признаков — фильтры, обертки и встраиваемые методы. Среди них числятся такие алгоритмы, как фильтры на основе корреляций Спирмена и Пирсона, критерий соответствия (Fit Criterion), QPFS, hill climbing filter и другие.\n",
        "\n",
        "Рассмотрим некоторые методы, которые предоставляет эта библиотека"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFxVcdYu9eCX",
        "outputId": "8b8d569e-4bfb-43ae-f6a4-e558cf849a33"
      },
      "source": [
        "!pip install ITMO_FS\n",
        "import ITMO_FS \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ITMO_FS\n",
            "  Downloading ITMO_FS-0.3.3-py3-none-any.whl (70 kB)\n",
            "\u001b[K     ,████████████████████████████████, 70 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (1.4.1)\n",
            "Collecting qpsolvers\n",
            "  Downloading qpsolvers-1.8.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (from ITMO_FS) (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn->ITMO_FS) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn->ITMO_FS) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ITMO_FS) (3.1.0)\n",
            "Collecting quadprog>=0.1.8\n",
            "  Downloading quadprog-0.1.11.tar.gz (121 kB)\n",
            "\u001b[K     ,████████████████████████████████, 121 kB 13.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: quadprog\n",
            "  Building wheel for quadprog (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quadprog: filename=quadprog-0.1.11-cp37-cp37m-linux_x86_64.whl size=290750 sha256=8db7b79340167bd8325337b9997fe10979467a043ec5edfe3928653bcc0ba967\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/4e/d7/41034ea11aeef1266df3cae546116cb6094e955c41ae3e2589\n",
            "Successfully built quadprog\n",
            "Installing collected packages: quadprog, qpsolvers, ITMO-FS\n",
            "Successfully installed ITMO-FS-0.3.3 qpsolvers-1.8.1 quadprog-0.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck-EhjoG-GpD"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from ITMO_FS.filters.univariate import select_best_percentage, select_k_best\n",
        "from ITMO_FS.filters.univariate import UnivariateFilter\n",
        "from ITMO_FS.filters.univariate import f_ratio_measure, pearson_corr\n",
        "from ITMO_FS.filters.univariate import VDM\n",
        "from ITMO_FS.filters.multivariate import MRMR\n",
        "from ITMO_FS.filters.multivariate import DISRWithMassive\n",
        "from ITMO_FS.filters.unsupervised.trace_ratio_laplacian import TraceRatioLaplacian\n",
        "\n",
        "x, y = make_classification(1000, 100, n_informative = 10, n_redundant = 30, n_repeated = 10, shuffle = False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OXblZ1GjA6D"
      },
      "source": [
        "# Univariate filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIIHrGWMjEsm"
      },
      "source": [
        "[Value Difference Metric](https://www.jair.org/index.php/jair/article/view/10182/24168#page=6) (VDM) - метрика расстояния, использующаяся в некоторых алгоритмах n ближайших соседей. Может использоваться для снижения влияния параметров, слабо связанных с целевой переменной, на эффективность классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egmH3KIi5TI",
        "outputId": "f85ae4b4-5bbc-4cd3-9a78-7e6c533d71e2"
      },
      "source": [
        "x_1 = np.array([[0, 0, 0, 0],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 0, 0, 2]])\n",
        "y_1 = np.array([0,\n",
        "              1,\n",
        "              1])\n",
        "vdm = VDM()\n",
        "vdm.run(x_1, y_1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 4.35355339, 4.        ],\n",
              "       [4.5       , 0.        , 0.5       ],\n",
              "       [4.        , 0.35355339, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSSqN755bZ4e"
      },
      "source": [
        "# Measures for univariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaM_BPkobr4K"
      },
      "source": [
        "Для этой группы методов достаточно передать входные данные и их классы. Всего в группе есть 10 методов:\n",
        "\n",
        "\n",
        "1. filters.univariate.**f_ratio_measure**(X, y)\t- Calculates Fisher score for features.\n",
        "2. filters.univariate.**gini_index**(X, y)\t- Gini index is a measure of statistical dispersion.\n",
        "3. filters.univariate.**su_measure**(X, y)\t- SU is a correlation measure between the features and the class calculated, via formula SU(X,Y) = 2 * I(X,Y) / (H(X) + H(Y))\n",
        "4. filters.univariate.**spearman_corr**(X, y)\t- Calculates spearman correlation for each feature.\n",
        "5. filters.univariate.**pearson_corr**(X, y)\t- Calculates pearson correlation for each feature.\n",
        "6. filters.univariate.**fechner_corr**(X, y)\t- Calculates Sample sign correlation (Fechner correlation) for each feature.\n",
        "7. filters.univariate.**kendall_corr**(X, y)\t- Calculates Sample sign correlation (Kendall correlation) for each feature.\n",
        "8. filters.univariate.**reliefF_measure**(X, y[, …])\t- Counts ReliefF measure for each feature\n",
        "9. filters.univariate.**chi2_measure**(X, y)\t- Calculates score for the test chi-squared statistic from X.\n",
        "10. filters.univariate.**information_gain**(X, y)\t- Calculates mutual information for each feature by formula, I(X,Y) = H(X) - H(X,Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UnjdD95anb0",
        "outputId": "015f167f-631f-4f53-c8b2-b45d9cb969bc"
      },
      "source": [
        "scores = f_ratio_measure(x, y)\n",
        "scores1 = pearson_corr(x, y)\n",
        "\n",
        "print(scores)\n",
        "print(scores1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.12646725e-01 1.02636539e-05 8.26286562e-02 4.35007377e-02\n",
            " 5.80353033e-02 1.68999384e-03 3.75561595e-06 9.46477364e-02\n",
            " 8.05012962e-04 4.55744633e-04 4.08304356e-03 1.43474056e-02\n",
            " 9.44156464e-02 7.00700767e-02 3.53148641e-02 3.28103435e-03\n",
            " 7.90283150e-02 5.02598321e-03 5.62442832e-02 1.95039528e-02\n",
            " 3.90874407e-02 1.80455733e-03 7.41054789e-02 1.13548353e-02\n",
            " 3.43347970e-04 3.50288142e-02 1.14063349e-01 3.64412950e-03\n",
            " 3.59740959e-06 5.71517115e-02 4.44869516e-03 5.40203735e-04\n",
            " 1.62135389e-02 1.94036310e-03 3.41507454e-04 3.04308281e-03\n",
            " 1.38896621e-02 7.25888243e-02 1.16805669e-02 5.96178417e-03\n",
            " 9.46477364e-02 9.46477364e-02 5.40203735e-04 9.46477364e-02\n",
            " 4.55744633e-04 3.50288142e-02 1.16805669e-02 3.41507454e-04\n",
            " 4.55744633e-04 3.64412950e-03 7.33302613e-07 1.16196068e-04\n",
            " 2.49707555e-03 2.14779023e-03 1.03578443e-02 6.78886839e-03\n",
            " 1.46441347e-03 2.31318087e-03 7.71785060e-07 2.15967377e-03\n",
            " 8.41655331e-05 1.64234468e-03 9.91381441e-04 1.50447374e-07\n",
            " 7.02420651e-04 1.11164883e-03 2.98195157e-03 1.82688321e-04\n",
            " 2.92767685e-04 2.16919293e-04 2.55860560e-06 2.50374521e-03\n",
            " 2.50013022e-04 1.16216604e-03 4.64853626e-03 2.24782159e-04\n",
            " 2.82061875e-03 1.89253871e-03 1.41956001e-03 4.32605944e-04\n",
            " 8.87478580e-04 1.18934136e-04 1.67529352e-03 1.64725163e-04\n",
            " 1.60902829e-04 4.11607705e-04 2.44297746e-03 9.92304709e-04\n",
            " 2.31563718e-03 2.66764475e-03 1.53592225e-04 1.24837866e-04\n",
            " 3.30032223e-04 3.61448297e-04 2.19889322e-03 1.73204811e-04\n",
            " 4.96598871e-04 7.44276933e-06 1.05108006e-03 4.52930275e-05]\n",
            "[-0.2797306   0.00320083 -0.23137538  0.20025243 -0.22223922 -0.03882752\n",
            " -0.00193953 -0.27165254  0.02973194 -0.02561023  0.06424804 -0.12689894\n",
            "  0.26183978 -0.24693814 -0.15809382  0.06792168 -0.25488157 -0.07713187\n",
            "  0.22160167  0.14069966 -0.19105936 -0.04198047 -0.23551319 -0.10444432\n",
            " -0.01883574 -0.17051545 -0.28977219  0.06012834  0.00190321 -0.24881347\n",
            " -0.0647063  -0.02319144  0.12737533  0.0445916  -0.01846168 -0.05586954\n",
            "  0.10417612 -0.24199648 -0.1065327   0.07873851 -0.27165254 -0.27165254\n",
            " -0.02319144 -0.27165254 -0.02561023 -0.17051545 -0.1065327  -0.01846168\n",
            " -0.02561023  0.06012834  0.0008992  -0.02813369  0.02187351 -0.03738726\n",
            "  0.08856412 -0.07907247  0.04033165  0.03954534  0.00084227  0.04910803\n",
            "  0.00964785 -0.03292102 -0.03272738 -0.00036324 -0.02576757  0.03300085\n",
            "  0.0569235  -0.01365864 -0.0180591  -0.01440521 -0.00167291 -0.04705939\n",
            "  0.01723139  0.05376484 -0.07561164  0.01287172  0.05514902  0.04341059\n",
            " -0.03739902 -0.03972233 -0.03089788  0.01068926 -0.04505032 -0.01307966\n",
            " -0.01590914  0.01998772  0.05301111  0.03017191 -0.04816703  0.04840171\n",
            " -0.01177831  0.00850355 -0.02043122  0.01973746  0.04420042  0.00786626\n",
            " -0.03164254  0.00242368  0.03145551 -0.00641157]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKhRGVHb0hM"
      },
      "source": [
        "# Cutting rules for univariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN1khlDmem0_"
      },
      "source": [
        "1. filters.univariate.**select_best_by_value**(value)\t\n",
        "2. filters.univariate.**select_worst_by_value**(value)\t\n",
        "3. filters.univariate.**select_k_best**(k)\t\n",
        "4. filters.univariate.**select_k_worst**(k)\t\n",
        "5. filters.univariate.**select_best_percentage**(percent)\t\n",
        "6. filters.univariate.**select_worst_percentage**(percent)\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJdNjdxKaBCT",
        "outputId": "38dd5eb2-0640-4398-8e51-b27f67361a42"
      },
      "source": [
        "ufilterBest = UnivariateFilter(f_ratio_measure, select_k_best(10))\n",
        "ufilterBest.fit(x, y)\n",
        "\n",
        "ufilterBestPercentage= UnivariateFilter(f_ratio_measure, select_best_percentage(0.1))\n",
        "ufilterBestPercentage.fit(x, y)\n",
        "\n",
        "print(ufilterBest.selected_features)\n",
        "print(ufilterBestPercentage.selected_features)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26, 0, 7, 40, 41, 43, 12, 2, 16, 22]\n",
            "[0, 2, 3, 4, 7, 11, 12, 13, 14, 16, 18, 19, 20, 22, 25, 26, 29, 32, 36, 37, 38, 40, 41, 43, 45, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkdDyfEciWkK"
      },
      "source": [
        "# Multivariate filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARK_poX_kMmV"
      },
      "source": [
        "Доступны следующие фильтры\n",
        "1. filters.multivariate.**DISRWithMassive**([…]) - Creates DISR (Double Input Symmetric Relevance) feature selection filter based on kASSI criterion for feature selection which aims at maximizing the mutual information avoiding, meanwhile, large multivariate density estimation.\n",
        "2. filters.multivariate.**FCBFDiscreteFilter**() -\tCreates FCBF (Fast Correlation Based filter) feature selection filter based on mutual information criteria for data with discrete features This filter finds best set of features by searching for a feature, which provides the most information about classification problem on given dataset at each step and then eliminating features which are less relevant than redundant\n",
        "3. filters.multivariate.**STIR**([n_features_to_keep]) -\tFeature selection using STIR algorithm.\n",
        "4. filters.multivariate.**TraceRatioFisher**(…) -\tCreates TraceRatio(similarity based) feature selection filter performed in supervised way, i.e fisher version\n",
        "5. filters.multivariate.**MIMAGA**(mim_size, …)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_zLs-5bjqKP"
      },
      "source": [
        "Пример Double Input Symmetric Relevance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhreAlEjph6",
        "outputId": "d1264d9b-f9d3-42e9-92c4-87af749e55fd"
      },
      "source": [
        "X = np.array([[1, 2, 3, 3, 1],[2, 2, 3, 3, 2], [1, 3, 3, 1, 3],[3, 1, 3, 1, 4],[4, 4, 3, 1, 5]])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "disr = DISRWithMassive(3)\n",
        "print(disr.fit_transform(X, y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 1]\n",
            " [2 2 2]\n",
            " [1 3 3]\n",
            " [3 1 4]\n",
            " [4 4 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ch0vpi9kot_"
      },
      "source": [
        "# Measures for multivariate filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po0jkk3AkuZC"
      },
      "source": [
        "1. filters.multivariate.**MIM**(selected_features, …)\t- Mutual Information Maximization feature scoring criterion.\n",
        "1. filters.multivariate.**MRMR**(selected_features, …)\t- Minimum-Redundancy Maximum-Relevance feature scoring criterion.\n",
        "1. filters.multivariate.**JMI**(selected_features, …)\t- Joint Mutual Information feature scoring criterion.\n",
        "1. filters.multivariate.**CIFE**(selected_features, …)\t- Conditional Infomax Feature Extraction feature scoring criterion.\n",
        "1. filters.multivariate.**MIFS**(selected_features, …)\t- Mutual Information Feature Selection feature scoring criterion.\n",
        "1. filters.multivariate.**CMIM**(selected_features, …)\t- Conditional Mutual Info Maximisation feature scoring criterion.\n",
        "1. filters.multivariate.**ICAP**(selected_features, …)\t- Interaction Capping feature scoring criterion.\n",
        "1. filters.multivariate.**DCSF**(selected_features, …)\t- Dynamic change of selected feature with the class scoring criterion.\n",
        "1. filters.multivariate.**CFR**(selected_features, …)\t- The criterion of CFR maximizes the correlation and minimizes the redundancy.\n",
        "1. filters.multivariate.**MRI**(selected_features, …)\t- Max-Relevance and Max-Independence feature scoring criteria.\n",
        "1. filters.multivariate.**IWFS**(selected_features, …)\t- Interaction Weight base feature scoring criteria.\n",
        "1. filters.multivariate.**generalizedCriteria**(…)\t- This feature scoring criteria is a linear combination of all relevance, redundancy, conditional dependency Given set of already selected features and set of remaining features on dataset X with labels y selects next feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha7oNJy6lAej"
      },
      "source": [
        "Пример использования Minimum-Redundancy Maximum-Relevance (MRMR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmxoDaXJiW6m",
        "outputId": "6c9c8062-4b6b-4bae-a6fc-b879781e5133"
      },
      "source": [
        "est = KBinsDiscretizer(n_bins=10, encode='ordinal') # ordinal - способ кодирования идентификатора бина как числовое значение\n",
        "data, target = np.array(x), np.array(y)\n",
        "est.fit(data)\n",
        "data = est.transform(data)\n",
        "selected_features = [1, 2]\n",
        "other_features = [i for i in range(0, data.shape[1]) if i not in selected_features]\n",
        "print(MRMR(np.array(selected_features), np.array(other_features), data, target))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.55825854 -0.56093276 -0.50623821 -0.34710248 -0.46306443 -0.46125139\n",
            " -0.47954247 -0.51589996 -0.48515566 -0.35819657 -0.37960375 -0.47230652\n",
            " -0.43401912 -0.39273988 -0.47125926 -0.46103338 -0.43915902 -0.49617427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgLXKYXylmem"
      },
      "source": [
        "# Unsupervised filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjeydSdUltWw"
      },
      "source": [
        "Пример TraceRatio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUJ2hBuclRuh",
        "outputId": "f4250380-3a65-4be8-bbd1-00af33d04c81"
      },
      "source": [
        "tracer = TraceRatioLaplacian(10)\n",
        "print(tracer.run(x, y)[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5 53  3 89 74 71 63 58 70 88]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeBriAIMlxOK"
      },
      "source": [
        "# Sparse filter methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddvLxZZxl08b"
      },
      "source": [
        "1. filters.sparse.**MCFS**(d[, k, p, scheme, sigma]) -\tPerforms the Unsupervised Feature Selection for Multi-Cluster Data algorithm.\n",
        "1. filters.sparse.**NDFS**(p[, c, k, alpha, beta, …]) -\tPerforms the Nonnegative Discriminative Feature Selection algorithm.\n",
        "1. filters.sparse.**RFS**(p[, gamma, …])\t- Performs the Robust Feature Selection via Joint L2,1-Norms Minimization algorithm.\n",
        "1. filters.sparse.**SPEC**(p[, k, gamma, sigma, …]) -\tPerforms the Spectral Feature Selection algorithm.\n",
        "1. filters.sparse.**UDFS**(p[, c, k, gamma, l, …]) -\tPerforms the Unsupervised Discriminative Feature Selection algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918QZZbgmI-Q"
      },
      "source": [
        "# Ensemble methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQn7lSL4mspS"
      },
      "source": [
        "1. ensembles.measure_based.**WeightBased**(filters)\n",
        "1. ensembles.model_based.**BestSum**(models, …)\n",
        "1. ensembles.ranking_based.**Mixed**(filters) - Performs feature selection based on several filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXzce2EBnCCC"
      },
      "source": [
        "# Embedded methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_TBKB2nDf3"
      },
      "source": [
        "1. embedded.**MOS**([model, loss, seed])\t- Performs Minimizing Overlapping Selection under SMOTE (MOSS) or under No-Sampling (MOSNS) algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keym-0L9nLcX"
      },
      "source": [
        "# Hybrid methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj17awItnOKz"
      },
      "source": [
        "1. hybrid.**FilterWrapperHybrid**(filter_, wrapper)\t\n",
        "1. hybrid.**Melif**(filter_ensemble[, scorer, verbose])\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-UqS0hVnVKj"
      },
      "source": [
        "# Wrapper methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykLAXONqnX45"
      },
      "source": [
        "1. wrappers.deterministic.**AddDelWrapper**(…[, …])\t- Creates add-del feature wrapper\n",
        "1. wrappers.deterministic.**BackwardSelection**(…)\t- Backward Selection removes one feature at a time until the number of features to be removed is reached.\n",
        "1. wrappers.deterministic.**RecursiveElimination**(…)\t- Performs a recursive feature elimination until the required number of features is reached.\n",
        "1. wrappers.deterministic.**SequentialForwardSelection**(…)\t- Sequentially Adds Features that Maximises the Classifying function when combined with the features already used TODO add theory about this method\n",
        "1. wrappers.deterministic.**qpfs_wrapper**(X, y, alpha)\t- Performs Quadratic Programming Feature Selection algorithm.\n",
        "1. wrappers.randomized.**HillClimbingWrapper**(…)\t\n",
        "1. wrappers.randomized.**SimulatedAnnealing**(…)\t- Performs feature selection using simulated annealing\n",
        "1. wrappers.randomized.**TPhMGWO**([wolfNumber, …])\t- Performs Grey Wolf optimization with Two-Phase Mutation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoxYiJMbrk9-"
      },
      "source": [
        "Пример работы [Backward Selection](https://itmo-fs.readthedocs.io/en/latest/generated/ITMO_FS.wrappers.deterministic.BackwardSelection.html?highlight=wrappers.deterministic.BackwardSelection) - алгоритм убирает по одному параметру, пока число убранных параметров не достигнет заданного. Возвращает имена оставшихся параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4AILPC4r1f8",
        "outputId": "675f7cfe-123d-4a63-a901-a012236de26a"
      },
      "source": [
        "from ITMO_FS.wrappers import BackwardSelection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x, y = make_classification(n_samples=100, n_features=20, n_informative=4, n_redundant=0, shuffle=False)\n",
        "data, target = np.array(x), np.array(y)\n",
        "\n",
        "model = BackwardSelection(LogisticRegression(), 15, 'f1_macro')\n",
        "model.fit(data, target)\n",
        "print(model.selected_features)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  2  9 11 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HfZ_losnsRi"
      },
      "source": [
        "# Источники\n",
        "Описание API - https://itmo-fs.readthedocs.io/en/latest/api.html  \n",
        "Статья на хабре - https://habr.com/ru/company/spbifmo/blog/516194/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-0uhVlzt0GT"
      },
      "source": [
        "# Ревью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQq9KdCst3Q6"
      },
      "source": [
        "## Передреев Дмитрий\n",
        "\n",
        "Туториал прошел. Если запускать все блоки кода по порядку, выдавалась ошибка, т.к. во втором блоке мы определяли x, y\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x, y = make_classification(1000, 100, n_informative = 10, n_redundant = 30, n_repeated = 10, shuffle = False)\n",
        "```\n",
        "\n",
        "а в третьем перезаписывали эти значения для демонстрации VDM.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x = np.array([[0, 0, 0, 0],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 0, 0, 2]])\n",
        "y = np.array([0,\n",
        "              1,\n",
        "              1])\n",
        "```\n",
        "\n",
        "Тогда зависящие от изначально заданных x, y блоки падали с ошибкой размерности. Пофиксил.\n",
        "\n",
        "Добавил короткое описание VDM и пример Backward Selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мартын Евгений\n",
        "Туториал прошел. Добавил описание строковой константы(комментарием)"
      ],
      "metadata": {
        "id": "-zykydOb6J6J"
      }
    }
  ]
}