{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natasha.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubanZ/ppa-for-da/blob/master/students/%D0%A1%D1%82%D1%80%D0%BE%D0%BA%D0%BE%D0%B2_%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D0%B9/Natasha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmY3skSUM6o8"
      },
      "source": [
        "# Предобработка текстовых данных с помощью фреймворка Natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esDsQB0cvmBM"
      },
      "source": [
        "Natasha решает базовые задачи NLP (natural language processing) для русского языка: токенизация, сегментация предложений, встраивание слов, морфология, лемматизация, нормализация фраз, синтаксический анализ, работа с NER, извлечение фактов. \n",
        "\n",
        "[Natasha](https://natasha.github.io/ner/) объединяет библиотеки проекта Natasha под одним удобным API:\n",
        "\n",
        "* [Razdel](https://natasha.github.io/razdel/) - токенизация, сегментация предложений для русского языка\n",
        "\n",
        "* [Navec](https://natasha.github.io/navec/) - вектора русских слов\n",
        "\n",
        "* [Slovnet](https://github.com/natasha/slovnet) - библиотека с методами глубокого обучения для русского NLP, компактные модели для русской морфологии, синтаксиса и NER.\n",
        "\n",
        "* [Yargy](https://github.com/natasha/yargy) - извлечение фактов на основе правил, аналогичное синтаксическому анализатору Tomita.\n",
        "\n",
        "Рассмотрим примеры использования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEVp8ulQplGO",
        "outputId": "85496243-e461-4bb8-f8a7-060f1850451e"
      },
      "source": [
        " !pip install \"natasha==1.4.0\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natasha==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.10.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.9.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.15.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.5.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.5.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha==1.4.0) (0.9.1)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha==1.4.0) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha==1.4.0) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha==1.4.0) (1.21.5)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha==1.4.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha==1.4.0) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha==1.4.0) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM4FX4IaqhKv"
      },
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqLHCMrxqnSI"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "\n",
        "names_extractor = NamesExtractor(morph_vocab)\n",
        "\n",
        "text = '''Студенты и сотрудники лаборатории Машинного обучения Университета ИТМО разработали библиотеку для Python, которая решает ключевую задачу машинного обучения.\n",
        "\n",
        "Расскажем, почему появился этот инструмент и что он умеет.\n",
        "Нехватка алгоритмов\n",
        "\n",
        "Одна из ключевых задач машинного обучения — снижение размерности данных. Дата-саентисты сокращают число переменных, вычленяя среди них значения, наибольшим образом влияющие на результат. После этой операции модель машинного обучения требует меньше памяти, работает быстрее и качественнее. Пример ниже показывает, что исключение дублирующих признаков увеличивает точность классификации с 0,903 до 0,943.\n",
        "\n",
        "Существует два подхода к уменьшению размерности — конструирование и выбор признаков. В областях вроде биоинформатики и медицины чаще используют последний, так как он позволяет выделить значимые признаки с сохранением семантики, то есть не меняет исходный смысл признаков. Однако в самых распространенных библиотеках машинного обучения на Python — scikit-learn, pytorch, keras, tensorflow — нет полноценного набора методов выбора признаков.\n",
        "\n",
        "Для решения этой проблемы студенты и аспиранты Университета ИТМО разработали открытую библиотеку — ITMO_FS. Над ней трудится команда под руководством Ивана Сметанникова, доцента факультета информационных технологий и программирования, заместителя заведующего лабораторией Машинного обучения. Ведущий разработчик — Никита Пильненьский, закончивший магистратуру «Машинное обучение и анализ данных». Теперь он поступает в аспирантуру.\n",
        "\n",
        "«За последние несколько лет в нашу лабораторию приходили запросы на решение задач, для которых не подходил стандартный инструментарий. Например, нам требовались ансамблирующие алгоритмы на основе объединения фильтров, или алгоритмы, учитывающие наличие заранее известных (экспертно-размеченных) значимых признаков.\n",
        "\n",
        "Посмотрев на существующие решения, мы пришли к выводу, что они не только не содержат необходимые нам инструменты, но и не являются достаточно гибкими для их возможной мягкой интеграции. В контексте того, что среди таких библиотек конкуренция слаба, мы решили сделать свою библиотеку, исправляющую большинство недостатков».\n",
        "\n",
        "— Иван Сметанников\n",
        "'''\n",
        "doc = Doc(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocdnCUWXrD5z"
      },
      "source": [
        "# Разделение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLQeWiTrIK8"
      },
      "source": [
        "После сегментации можно работать как с отдельными токенами, так и с целыми предложениями (которые в себе также содержат токены)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWiFLPcqtDp",
        "outputId": "039dac9f-2625-442f-976b-97539188c438"
      },
      "source": [
        "doc.segment(segmenter)\n",
        "doc.tokens[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocToken(stop=8, text='Студенты'),\n",
              " DocToken(start=9, stop=10, text='и'),\n",
              " DocToken(start=11, stop=21, text='сотрудники'),\n",
              " DocToken(start=22, stop=33, text='лаборатории'),\n",
              " DocToken(start=34, stop=43, text='Машинного')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6F0KoA6w3G",
        "outputId": "afd53449-9e18-4bf2-bfc1-10555c7488ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc.sents[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocSent(stop=156, text='Студенты и сотрудники лаборатории Машинного обуче..., tokens=[...]),\n",
              " DocSent(start=158, stop=216, text='Расскажем, почему появился этот инструмент и что ..., tokens=[...]),\n",
              " DocSent(start=217, stop=310, text='Нехватка алгоритмов\\n\\nОдна из ключевых задач маш..., tokens=[...]),\n",
              " DocSent(start=311, stop=424, text='Дата-саентисты сокращают число переменных, вычлен..., tokens=[...]),\n",
              " DocSent(start=425, stop=526, text='После этой операции модель машинного обучения тре..., tokens=[...])]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1pYrG_0rglP"
      },
      "source": [
        "# Морфология"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMMpCQzTrit_"
      },
      "source": [
        "Библиотека умеет проводить морфологический анализ, можно работать снова с каждым токеном. Также уже есть встроенный \"красивый\" вывод признаков\n",
        "\n",
        "Зависит от шага с разделением и дополняет уже существующую информацию о токенах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2q2v7hyrjeA",
        "outputId": "43698655-d19a-46c7-d6ea-f7b3d5d4eaed"
      },
      "source": [
        "doc.tag_morph(morph_tagger)\n",
        "doc.tokens[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocToken(stop=8, text='Студенты', pos='NOUN', feats=<Anim,Nom,Masc,Plur>),\n",
              " DocToken(start=9, stop=10, text='и', pos='CCONJ'),\n",
              " DocToken(start=11, stop=21, text='сотрудники', pos='NOUN', feats=<Anim,Nom,Masc,Plur>),\n",
              " DocToken(start=22, stop=33, text='лаборатории', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
              " DocToken(start=34, stop=43, text='Машинного', pos='ADJ', feats=<Gen,Pos,Neut,Sing>)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbdDkKr_7I5M",
        "outputId": "cda021dd-ef53-4712-8084-aacbd371720e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc.sents[0].morph.print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Студенты NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\n",
            "                   и CCONJ\n",
            "          сотрудники NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\n",
            "         лаборатории NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "           Машинного ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "            обучения NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "        Университета PROPN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "                ИТМО PROPN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "         разработали VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "          библиотеку NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "                 для ADP\n",
            "              Python PROPN|Foreign=Yes\n",
            "                   , PUNCT\n",
            "             которая PRON|Case=Nom|Gender=Fem|Number=Sing\n",
            "              решает VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "            ключевую ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
            "              задачу NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "           машинного ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "            обучения NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "                   . PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_DLAal4sJFO"
      },
      "source": [
        "# Лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Roov1qssfo_"
      },
      "source": [
        "Зависит от шага с морфологическим разбором и дополняет уже существующую информацию о токенах\n",
        "\n",
        "Выведем первые 15 примеров приведения слова к его нормальной форме"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxrJaGuxspNo",
        "outputId": "49d9f618-66e8-4cfc-8be5-6cf3fc46ab43"
      },
      "source": [
        "for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "    \n",
        "doc.tokens[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocToken(stop=8, text='Студенты', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='студент'),\n",
              " DocToken(start=9, stop=10, text='и', pos='CCONJ', lemma='и'),\n",
              " DocToken(start=11, stop=21, text='сотрудники', pos='NOUN', feats=<Anim,Nom,Masc,Plur>, lemma='сотрудник'),\n",
              " DocToken(start=22, stop=33, text='лаборатории', pos='NOUN', feats=<Inan,Gen,Fem,Sing>, lemma='лаборатория'),\n",
              " DocToken(start=34, stop=43, text='Машинного', pos='ADJ', feats=<Gen,Pos,Neut,Sing>, lemma='машинный')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEOxvfFg7TVB",
        "outputId": "86bb77db-e29b-48a9-dd40-e1bb528f3d0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "{_.text: _.lemma for _ in doc.tokens[:15]}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " 'Python': 'python',\n",
              " 'ИТМО': 'итмо',\n",
              " 'Машинного': 'машинный',\n",
              " 'Студенты': 'студент',\n",
              " 'Университета': 'университет',\n",
              " 'библиотеку': 'библиотека',\n",
              " 'для': 'для',\n",
              " 'и': 'и',\n",
              " 'которая': 'который',\n",
              " 'лаборатории': 'лаборатория',\n",
              " 'обучения': 'обучение',\n",
              " 'разработали': 'разработать',\n",
              " 'решает': 'решать',\n",
              " 'сотрудники': 'сотрудник'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8bMbIWtgUa"
      },
      "source": [
        "# Синтаксический разбор"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBbJIZiytj0g"
      },
      "source": [
        "Зависит от шага с разделением на токены, а именно использует информацию о предложениях"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG0PwdXqts7O",
        "outputId": "d7863e7e-0180-4422-b178-054fda7a608f"
      },
      "source": [
        "doc.parse_syntax(syntax_parser)\n",
        "doc.tokens[:5]\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocToken(stop=8, text='Студенты', id='1_1', head_id='1_9', rel='nsubj'),\n",
              " DocToken(start=9, stop=10, text='и', id='1_2', head_id='1_3', rel='cc'),\n",
              " DocToken(start=11, stop=21, text='сотрудники', id='1_3', head_id='1_1', rel='conj'),\n",
              " DocToken(start=22, stop=33, text='лаборатории', id='1_4', head_id='1_3', rel='nmod'),\n",
              " DocToken(start=34, stop=43, text='Машинного', id='1_5', head_id='1_6', rel='amod')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHSWC7K7cN3",
        "outputId": "d1e99397-279c-45f3-fb65-ba91306e52f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc.sents[0].syntax.print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ┌────────► Студенты     nsubj\n",
            "  │       ┌► и            cc\n",
            "  │     ┌─└─ сотрудники   \n",
            "  │ ┌─┌─└──► лаборатории  nmod\n",
            "  │ │ │   ┌► Машинного    amod\n",
            "  │ │ └──►└─ обучения     nmod\n",
            "  │ └────►┌─ Университета nmod\n",
            "  │       └► ИТМО         nmod\n",
            "┌─└───────┌─ разработали  \n",
            "│     ┌─┌─└► библиотеку   obj\n",
            "│     │ │ ┌► для          case\n",
            "│     │ └►└─ Python       nmod\n",
            "│     │ ┌──► ,            punct\n",
            "│     │ │ ┌► которая      nsubj\n",
            "│     └►└─└─ решает       acl:relcl\n",
            "│     │   ┌► ключевую     amod\n",
            "│   ┌─└──►└─ задачу       obj\n",
            "│   │     ┌► машинного    amod\n",
            "│   └────►└─ обучения     nmod\n",
            "└──────────► .            punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b_g6txAt1nl"
      },
      "source": [
        "# Распознование именованных сущностей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlNi5eFnt4tE"
      },
      "source": [
        "Зависит от шага с разделением на токены"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5NwlP6LuB6m",
        "outputId": "87e172b7-101e-4998-b65d-6ff43520835f"
      },
      "source": [
        "doc.tag_ner(ner_tagger)\n",
        "doc.spans[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...]),\n",
              " DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...]),\n",
              " DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...]),\n",
              " DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...]),\n",
              " DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M19i_Ic7iJ0",
        "outputId": "e9f5dd7a-012d-44ce-d887-9634407389c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc.ner.print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Студенты и сотрудники лаборатории Машинного обучения Университета ИТМО\n",
            "                                  ORG─────────────── ORG──────────────\n",
            " разработали библиотеку для Python, которая решает ключевую задачу \n",
            "машинного обучения.\n",
            "Расскажем, почему появился этот инструмент и что он умеет.\n",
            "Нехватка алгоритмов\n",
            "Одна из ключевых задач машинного обучения — снижение размерности \n",
            "данных. Дата-саентисты сокращают число переменных, вычленяя среди них \n",
            "значения, наибольшим образом влияющие на результат. После этой \n",
            "операции модель машинного обучения требует меньше памяти, работает \n",
            "быстрее и качественнее. Пример ниже показывает, что исключение \n",
            "дублирующих признаков увеличивает точность классификации с 0,903 до \n",
            "0,943.\n",
            "Существует два подхода к уменьшению размерности — конструирование и \n",
            "выбор признаков. В областях вроде биоинформатики и медицины чаще \n",
            "используют последний, так как он позволяет выделить значимые признаки \n",
            "с сохранением семантики, то есть не меняет исходный смысл признаков. \n",
            "Однако в самых распространенных библиотеках машинного обучения на \n",
            "Python — scikit-learn, pytorch, keras, tensorflow — нет полноценного \n",
            "набора методов выбора признаков.\n",
            "Для решения этой проблемы студенты и аспиранты Университета ИТМО \n",
            "                                               ORG────────────── \n",
            "разработали открытую библиотеку — ITMO_FS. Над ней трудится команда \n",
            "под руководством Ивана Сметанникова, доцента факультета информационных\n",
            "                 PER───────────────                                   \n",
            " технологий и программирования, заместителя заведующего лабораторией \n",
            "Машинного обучения. Ведущий разработчик — Никита Пильненьский, \n",
            "ORG───────────────                        PER────────────────  \n",
            "закончивший магистратуру «Машинное обучение и анализ данных». Теперь \n",
            "он поступает в аспирантуру.\n",
            "«За последние несколько лет в нашу лабораторию приходили запросы на \n",
            "решение задач, для которых не подходил стандартный инструментарий. \n",
            "Например, нам требовались ансамблирующие алгоритмы на основе \n",
            "объединения фильтров, или алгоритмы, учитывающие наличие заранее \n",
            "известных (экспертно-размеченных) значимых признаков.\n",
            "Посмотрев на существующие решения, мы пришли к выводу, что они не \n",
            "только не содержат необходимые нам инструменты, но и не являются \n",
            "достаточно гибкими для их возможной мягкой интеграции. В контексте \n",
            "того, что среди таких библиотек конкуренция слаба, мы решили сделать \n",
            "свою библиотеку, исправляющую большинство недостатков».\n",
            "— Иван Сметанников\n",
            "  PER─────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzVMqHm7uOT1"
      },
      "source": [
        "Затем такие сущности можно нормализовать\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMtsX3VEuSZQ",
        "outputId": "94cdda14-dec7-4872-a8c8-f0e9629ac9fc"
      },
      "source": [
        "for span in doc.spans:\n",
        "   span.normalize(morph_vocab)\n",
        "doc.spans[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинного обучения'),\n",
              " DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университета ИТМО'),\n",
              " DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университета ИТМО'),\n",
              " DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...], normal='Ивана Сметанникова'),\n",
              " DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинного обучения')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh6ORKDv7n78",
        "outputId": "07f38724-1b25-4a8a-cc3c-87c3edf5e7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "{_.text: _.normal for _ in doc.spans if _.text != _.normal}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiG6UODBubvP"
      },
      "source": [
        "А также рзделить на составные чати (имя, фамилия и тд)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwEtYGQzuhCe",
        "outputId": "ed4f2244-3ace-423d-aa99-21e994529ba9"
      },
      "source": [
        "for span in doc.spans:\n",
        "   if span.type == PER:\n",
        "       span.extract_fact(names_extractor)\n",
        "\n",
        "doc.spans[:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocSpan(start=34, stop=52, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинного обучения'),\n",
              " DocSpan(start=53, stop=70, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университета ИТМО'),\n",
              " DocSpan(start=1130, stop=1147, type='ORG', text='Университета ИТМО', tokens=[...], normal='Университета ИТМО'),\n",
              " DocSpan(start=1233, stop=1251, type='PER', text='Ивана Сметанникова', tokens=[...], normal='Ивана Сметанникова', fact=DocFact(slots=[...])),\n",
              " DocSpan(start=1355, stop=1373, type='ORG', text='Машинного обучения', tokens=[...], normal='Машинного обучения')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKL_k62Y7vBk",
        "outputId": "bc9aa152-2c5c-4aaf-8d4e-978bdf35e081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "{_.normal: _.fact.as_dict for _ in doc.spans if _.type == PER}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Иван Сметанников': {'first': 'Иван', 'last': 'Сметанников'},\n",
              " 'Ивана Сметанникова': {'first': 'Ивана', 'last': 'Сметанникова'},\n",
              " 'Никита Пильненьский': {'first': 'Никита', 'last': 'Пильненьский'}}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjsNtbOIK5J5"
      },
      "source": [
        "# Источники\n",
        "\n",
        "https://github.com/natasha\n",
        "\n",
        "https://natasha.github.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFfC8jrKK8PA"
      },
      "source": [
        "# Ревью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnPNcKg3LAxp"
      },
      "source": [
        "## Передреев Дмитрий\n",
        "\n",
        "Туториал прошел. Добавил заголовок и ссылки на документацию модулей проекта - в них более подробно разобраны примеры использования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwyCG6e652D"
      },
      "source": [
        "##Рубан Александр\n",
        "Туториал прошел. Изменил ввыод на более читаемый"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мартын Евгений\n",
        "Туториал прошел. Привязал зависимости к конкретной версии. На случай изменения публичного API"
      ],
      "metadata": {
        "id": "nHgPKNiDYklb"
      }
    }
  ]
}